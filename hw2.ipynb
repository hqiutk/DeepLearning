{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bbf7c17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f22d0d72aa3d54675e61989310d8197",
     "grade": false,
     "grade_id": "cell-8b90bccda6f5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# COSC 424/525 â€“ Deep Learning, Spring 2026\n",
    "## Homework 2: BP and NN Review\n",
    "\n",
    "This homework, again, has ONE problem that revisits the toy example discussed in class. You will apply perceptron and multi-layer perceptron (MLP) and gain insights into how gradient descent works and how errors are propagated through the network to update weights. You must strictly follow the instructions and provide the required outputs at each step. The only file you should submit is the notebook.\n",
    "\n",
    "Both 424/525 students will use both Mary and John's ratings, hence a 2-dimensional classification problem\n",
    "\n",
    "**Problem:** It is Friday night and you'd like to watch a movie. You are considering \"Gravity\" and want to choose a movie you are likely to enjoy. You do not want to spend an hour of your weekend watching a movie only to discover that you dislike it. To help decide, you called your two friends, Mary and John, and ask for their ratings of \"Gravity\", which they provide. You are also aware of their ratings for 11 other movies that you have already watched and know whether you \"liked\" or \"disliked\".\n",
    "\n",
    "**Training Data:**\n",
    "- Movies that Mary rated that I liked, [2.5, 3.5, 3.5, 4.5, 4.5]\n",
    "- Movies that John rated that I liked, in the same order as above, [5, 5, 4, 5, 4]\n",
    "- Movies that Mary rated that I disliked, [1, 1, 1.5, 2.5, 2.5, 2.5]\n",
    "- Movies that John rated that I disliked, in the same order as above, [5, 4, 4, 3, 1.5, 1]\n",
    "\n",
    "**Testing Data:**\n",
    "- Mary's rating for \"Gravity\" is 3\n",
    "- John's rating for \"Gravity\" is 3\n",
    "\n",
    "**Question:**\n",
    "Should I watch \"Gravity\"? (or put it another way: will I \"like\" or \"dislike\" Gravity?)\n",
    "\n",
    "You will solve the problem using two learning approaches, perceptron and MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569d1e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7717f2a22da2864edacc4ae1fe6656bd",
     "grade": false,
     "grade_id": "cell-18de7b18f938",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# **COURSE: ENTER 424 OR 525**\n",
    "\n",
    "**Fill in your course number in the next cell (424 or 525).** Run that cell first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7a3b9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6bdd88de452997b108b0904c4b227ff",
     "grade": false,
     "grade_id": "course_number",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set your course number: 424 or 525\n",
    "\n",
    "# YOUR CODE HERE\n",
    "course = 525   # Change to 424 if you are in COSC 424\n",
    "\n",
    "print(f\"Course: {course}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262cc78b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a759b21ca5b3b0834a949ab5dceb962",
     "grade": false,
     "grade_id": "cell-b582dd59a9c6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Approach 1: Single-layer perceptron\n",
    "\n",
    "The following figure shows the structure of a perceptron (single-layer) to solve the classification problem of the toy example, where $x_1$ indicates Mary's rating and $x_2$ indicates John's rating, $w_1$ and $w_2$ are weights to the corresponding ratings, and $-w_0$ is the bias. The forward pass follows the following criterion:\n",
    "\n",
    "If $w_1 x_1 + w_2 x_2 > w_0$, then $z = 1$; otherwise, $z = -1$\n",
    "\n",
    "With minor rearranging, we have\n",
    "\n",
    "If $w_1 x_1 + w_2 x_2 - w_0 > 0$, then $z = 1$; otherwise, $z = -1$\n",
    "\n",
    "Using vector representation, with $\\mathbf{a} = [w_1, w_2, -w_0]$ and $\\mathbf{y} = [x_1, x_2, 1]$, we have\n",
    "\n",
    "If $\\mathbf{a}^T \\mathbf{y} > 0$, then $z = 1$; otherwise, $z = -1$\n",
    "\n",
    "![Perceptron Structure](perceptron_structure.png)\n",
    "\n",
    "Note that in the above description, the output $z$ is either 1 or -1; instead of either 1 or 0. This is in part due to the design of the cost function (see (a) for more details), and in part due to the fact that it is relatively easier to differentiate between negative and positive, rather than 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f68c95",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26e12a8ca9168d29e3737ac95cf1b106",
     "grade": false,
     "grade_id": "cell-216b106066f8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (a) On the objective function\n",
    "\n",
    "The objective function of Perceptron is different (but more interesting in personal opinion) from the least square error used in MLP,\n",
    "\n",
    "$$\n",
    "J_P(\\mathbf{a}) = \\sum_{\\mathrm{ms}} (-\\mathbf{a}^T \\mathbf{y})\\, t\n",
    "$$\n",
    "\n",
    "where $t$ is the target value, either 1 (like) or -1 (dislike); \"ms\" stands for the set of misclassified samples. The cost function (or objective function), $J_P(\\mathbf{a})$, actually calculates the total number of misclassified training samples. You need to provide a justification how the cost function behaves that way.\n",
    "\n",
    "**Hint:** since \"ms\" only contains the misclassified samples, answer this question from two scenarios, what happens when the sample should be \"liked\" but misclassified as \"dislike\"; and what happens when the sample should be \"disliked\" but misclassified as \"liked\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972e12c",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81e2ea6d2d562ee853a0f58a7d506fbd",
     "grade": true,
     "grade_id": "cell-3fd53eaa65ff",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "*Your justification:*\n",
    "\n",
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef6847",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46582f5151ef718968ae6ce47202f26e",
     "grade": false,
     "grade_id": "cell-4273035a5d43",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (b) On learning (525 only)\n",
    "\n",
    "In the above cost function, the learning task is to find the $\\mathbf{a}^*$ that minimizes $J_P(\\mathbf{a})$. To do so, we use gradient descent, $\\mathbf{a}^{k+1} = \\mathbf{a}^k - c \\cdot \\nabla J_P(\\mathbf{a})$ where \"grad\" indicates the gradient, and $c$ is the learning rate. Assume $c=1$, we then have\n",
    "\n",
    "$$\n",
    "w^{k+1} = w^k + \\sum_{\\mathrm{ms}} \\mathbf{x}\\, (T - z)\n",
    "$$\n",
    "\n",
    "$$\n",
    "-w_0^{k+1} = -w_0^k + \\sum_{\\mathrm{ms}} (T - z)\n",
    "$$\n",
    "\n",
    "Show the detailed derivation steps that arrive at these update rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2aed2",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47ccb9cc24a9bd5d4eb94ea7252c04d3",
     "grade": true,
     "grade_id": "cell-b619e3a41b49",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "*Your derivation:*\n",
    "\n",
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80bb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9f0e23a708c9aa308705de1f9fe051a",
     "grade": true,
     "grade_id": "test_b_525_only",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For instructor use only (auto-check). Do not remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad746b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f84ff6a79fe72d715f1a3c270fe6e3a7",
     "grade": false,
     "grade_id": "cell-eab854554e84",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (c) One-step update\n",
    "\n",
    "Suppose the initial value of the weights are $w_1^0 = 0.3$, $w_2^0 = -0.3$, $w_0^0 = 0.1$, for an input of $[x_1, x_2] = [2.5, 5]$, and $T = 1$ (note that this is the first sample in the training set), show the updated result of $w_1^1$, $w_2^1$, $w_0^1$.\n",
    "\n",
    "**Note:** Perceptron uses a different stopping criterion from the norm-based one: it stops when **ALL** training samples are correctly classified (i.e., the number of misclassified samples equals 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb031669",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "928e236a869dafdec7f8e01da63ecb5c",
     "grade": false,
     "grade_id": "cell-7a98e8737514",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (c) One-step update: initial w10=0.3, w20=-0.3, w00=0.1; input [2.5, 5], T=1.\n",
    "# Define: z, w11, w21, w01\n",
    "import numpy as np\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"=== One-step update (c) ===\")\n",
    "print(f\"a^T y = {a_T_y}\")\n",
    "print(f\"z = {z}\")\n",
    "print(f\"w11 = {w11}, w21 = {w21}, w01 = {w01}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a13ac4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67e6229347e2ab27948a99089488d2de",
     "grade": true,
     "grade_id": "cell-52649a2168dd",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For instructor use only (auto-check). Do not remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac0e2c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f17f031bdef2cc300aef84da04309580",
     "grade": false,
     "grade_id": "cell-a7e19c7d3e1f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (d) One epoch of online learning\n",
    "\n",
    "One epoch means one full pass through all 11 samples in the training set, that is, 11 iterations. There are two updating schemes: **batch update** vs. **online update**.\n",
    "\n",
    "- **Online learning**: update weights after each individual sample (i.e., at the end of each iteration).\n",
    "- **Batch learning**: accumulate the errors across all samples and only update the weights at the end of each epoch.\n",
    "\n",
    "In this approach, we choose **online learning**. Repeat (c) to iterate through all the 11 samples in the training set (one epoch).\n",
    "\n",
    "Provide a scatter plot of all the 11 samples. On the same figure, plot the **initial decision boundary** and the **decision boundary after the first epoch**.\n",
    "\n",
    "**Hint:** The decision boundary is essentially $\\mathbf{a}^T \\mathbf{y} = 0$ or $w_1 x_1 + w_2 x_2 - w_0 = 0$, which is a line. Use the initial $w$'s given in (c) to plot the initial boundary. Use the updated $w$'s at the end of the first epoch to plot the updated boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4c08e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0d0b3d35455eee676717f0fff6dc2e1",
     "grade": false,
     "grade_id": "cell-23df92e11a18",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (d) One epoch of online learning through all 11 samples.\n",
    "# Define: w1_epoch1, w2_epoch1, w0_epoch1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"=== After epoch 1 (d) ===\")\n",
    "print(f\"w1_epoch1 = {w1_epoch1}, w2_epoch1 = {w2_epoch1}, w0_epoch1 = {w0_epoch1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f3d4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2b2e86938546fee64f69ead267ffcf4",
     "grade": true,
     "grade_id": "cell-94cb6e685431",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For instructor use only (auto-check). Do not remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509c190",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "609fc1e969f39171836592c784b9d1f2",
     "grade": false,
     "grade_id": "cell-d684f2383c21",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (e) Stopping criterion\n",
    "\n",
    "Repeat (d) for multiple epochs (maximum 150 epochs). In each epoch, re-accumulate the number of misclassified samples. At the end of each epoch, check if the number of misclassified samples equals 0. If it does, then stop the learning early; otherwise, stop after the maximum preset epochs (150 epochs).\n",
    "\n",
    "Redo the scatter plot as you did in (d). On the same figure, for every 20 epochs (20, 40, 60, 80, 100, ...  unless you had early stop), plot the decision boundary at the end of that epoch using the updated $w$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194ff91",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb6cfe238246966b8dbf3dc395d29a3e",
     "grade": false,
     "grade_id": "cell-32a1fe3af1ec",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (e) Run up to 150 epochs of online learning. Stop early if 0 misclassified.\n",
    "# Define: w1_final, w2_final, w0_final, boundaries_at_epochs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"=== Perceptron final weights (e) ===\")\n",
    "print(f\"w1_final = {w1_final}, w2_final = {w2_final}, w0_final = {w0_final}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01d907",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbe7e487b0c0ff1d6d36793d7c0c564a",
     "grade": true,
     "grade_id": "cell-59079667e853",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For instructor use only (auto-check). Do not remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1617e28",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89cf5ce30d0e75bc8e835f1e82dc2685",
     "grade": false,
     "grade_id": "cell-311f663c1b3b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (f) Gravity prediction\n",
    "\n",
    "Using your trained perceptron weights (`w1_final`, `w2_final`, `w0_final`), predict whether you will \"like\" or \"dislike\" Gravity. Mary's rating for Gravity is 3, John's rating is 3. Set `gravity_prediction` to 1 for \"like\" or -1 for \"dislike\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360b58f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66087d40736c6d46950511d4d81b2f10",
     "grade": false,
     "grade_id": "cell-f323bbbf2669",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (f) Gravity prediction (Mary=3, John=3). Define: gravity_prediction (1 or -1).\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"=== Gravity prediction (f) ===\")\n",
    "print(f\"a^T y = {a_T_y}\")\n",
    "print(f\"gravity_prediction (1=like, -1=dislike): {gravity_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddb193",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ee253d2981124673a4bd513ebb0746a",
     "grade": true,
     "grade_id": "cell-53f357297b02",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For instructor use only (auto-check). Do not remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9bd37f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "280c24d505f243175ab20c47661120a6",
     "grade": false,
     "grade_id": "cell-df5f35c01e9d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (g) Compare decision boundaries\n",
    "\n",
    "1. Provide a clean scatter plot of the samples.\n",
    "2. On this plot, draw the **final decision boundary from Perceptron** (from part e).\n",
    "3. On the same plot, draw the **decision boundary from the minimum distance classifier** (as you did in HW1).\n",
    "\n",
    "**Hint:** The minimum distance classifier boundary is given by $\\|\\mathbf{x} - \\mathbf{m}_1\\| = \\|\\mathbf{x} - \\mathbf{m}_2\\|$, where $\\mathbf{x} = [x_1, x_2]^T$, $\\mathbf{m}_1 = [m_{11}, m_{12}]^T$ (mean of liked), and $\\mathbf{m}_2 = [m_{21}, m_{22}]^T$ (mean of disliked). This leads to:\n",
    "\n",
    "$$(-2 m_{11} + 2 m_{21}) x_1 + (-2 m_{12} + 2 m_{22}) x_2 + (m_{11}^2 + m_{12}^2 - m_{21}^2 - m_{22}^2) = 0$$\n",
    "\n",
    "which is a line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470c50d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2416ba2261d85a5a1bdc35ec3a14dc68",
     "grade": false,
     "grade_id": "cell-8c5d1cf53cf8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (g) Compare decision boundaries: Perceptron vs. minimum distance classifier.\n",
    "# Define: m1, m2 (mean vectors of liked and disliked classes)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632d276",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4c4580e5708ba9cf3e4b7a5828539f6",
     "grade": true,
     "grade_id": "cell-56cbb81d1555",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For instructor use only (auto-check). Do not remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e4aa0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fac5e7c43693a8c392736fc5ce66dbc",
     "grade": false,
     "grade_id": "cell-b86602aa88a7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Bonus: 1NN decision boundary\n",
    "\n",
    "**(Bonus, +10 points for both 424 and 525):** On the same figure, plot the decision boundary for 1NN. Note that since 1NN is non-parametric, you cannot find an explicit function to plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313e638",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "807cc2a1ecd733ebfa789690b3f7fea1",
     "grade": false,
     "grade_id": "cell-dff6ec5c6554",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (g) Bonus: 1NN decision boundary on the same comparison plot.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
